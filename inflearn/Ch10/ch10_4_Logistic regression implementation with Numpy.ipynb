{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "datasets = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = datasets[\"data\"]\n",
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = datasets[\"target\"]\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data.reshape(-1,1)\n",
    "y_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_data)\n",
    "y_data = enc.transform(y_data).toarray()\n",
    "y_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_data_minmax = min_max_scaler.fit_transform(x_data)\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [1.        , 0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [1.        , 0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = np.ones(x_data_minmax.shape[0])\n",
    "x_data_minmax = np.column_stack((x_0, x_data_minmax)) \n",
    "\n",
    "\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고. np.column_stack()\n",
    "Stack 1-D arrays as columns into a 2-D array.\n",
    "\n",
    "Take a sequence of 1-D arrays and stack them as columns to make a single 2-D array. 2-D arrays are stacked as-is, just like with hstack. 1-D arrays are turned into 2-D columns first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74039972, 0.87900992, 0.39592   , 0.77698922, 0.698704  ],\n",
       "       [0.01859898, 0.74324088, 0.09284932, 0.26521326, 0.9850767 ],\n",
       "       [0.83815136, 0.18965369, 0.20894612, 0.5704041 , 0.16314294]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.uniform(size=(3,5)) # 왜 3* 5로 weight를 만들지? 5는 알겠는데 3은 모르겠다. 3은 구분되는게 3개니까 k개 클래스가 있다. 즉 k = 3\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1., 0., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
       "  array([0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
       "  array([1., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0., 1., 0., 1., 0., 0.]),\n",
       "  array([0., 1., 0., 0., 0., 0., 0., 1., 0., 1.])],\n",
       " array([0.01859898, 0.11524675, 0.21189453, 0.3085423 , 0.40519007,\n",
       "        0.50183784, 0.59848562, 0.69513339, 0.79178116, 0.88842893,\n",
       "        0.9850767 ]),\n",
       " <a list of 5 Lists of Patches objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    e = np.exp(z)\n",
    "    p = e / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (150, 5), (3, 5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape, x_data_minmax.shape, weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_function(y, x, weights):\n",
    "    z = x_data_minmax.dot(weights.T) # W.T * X 부분 :3*5->5*3 되고 이를 dot 하면 150*5 x 5*3 = 150 * 3\n",
    "    result = -np.sum(np.sum((y * np.log(softmax(z))), axis=1).reshape(-1,1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.0380421538121"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_function(y_data, x_data_minmax, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gradient(y, x, initial_weights, iterations = 500000, alpha = 0.001):\n",
    "    cost_history = []\n",
    "    theta_history = []\n",
    "    m = y.shape[0]\n",
    "    theta = np.copy(initial_weights)\n",
    "    \n",
    "    number_of_classes = theta.shape[0]\n",
    "    number_of_weights = theta.shape[1]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        original_theta = np.copy(theta)  \n",
    "        for k in range(number_of_classes):  # theta[0] = 3\n",
    "            for j in range(number_of_weights):  # theta[1] = 5\n",
    "                partial_x = x[:, j]\n",
    "                partial_entropy = y - softmax(x.dot(original_theta.T))\n",
    "                theta[k][j] = original_theta[k][j] + (alpha*partial_entropy[:,k].dot(partial_x.T))/m\n",
    "        if (_ % 10000) == 0:\n",
    "            print(cross_entropy_function(y,x,theta)/m)\n",
    "            cost_history.append(cross_entropy_function(y,x,theta))\n",
    "    return theta, cost_history               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3266406351640767\n",
      "0.7866795660773792\n",
      "0.6355289091552657\n",
      "0.5551441686707586\n",
      "0.5033182812457716\n",
      "0.46597425252306096\n",
      "0.4371557093540883\n",
      "0.4138809242827577\n",
      "0.39446954147150737\n",
      "0.377889684636821\n",
      "0.36346574605342663\n",
      "0.35073306532390625\n",
      "0.3393594241782117\n",
      "0.3290997381099756\n",
      "0.31976846733128655\n",
      "0.31122206086044374\n",
      "0.30334736791189004\n",
      "0.2960537482434219\n",
      "0.28926755732622844\n",
      "0.282928202797947\n",
      "0.2769852679655028\n",
      "0.27139637659190424\n",
      "0.26612558306472267\n",
      "0.2611421416010665\n",
      "0.25641955329011645\n",
      "0.25193481973200543\n",
      "0.24766785230849048\n",
      "0.24360100009176866\n",
      "0.23971866918052492\n",
      "0.23600701320365475\n",
      "0.23245367973831113\n",
      "0.22904760103896663\n",
      "0.22577882016592563\n",
      "0.22263834560775744\n",
      "0.21961802900183916\n",
      "0.21671046170387542\n",
      "0.21390888683560452\n",
      "0.2112071241181813\n",
      "0.20859950532647323\n",
      "0.20608081861302405\n",
      "0.20364626027669744\n",
      "0.2012913928100208\n",
      "0.19901210826615173\n",
      "0.19680459615259166\n",
      "0.19466531519303562\n",
      "0.1925909684077651\n",
      "0.1905784810519442\n",
      "0.18862498102412986\n",
      "0.18672778141737564\n",
      "0.1848843649350221\n"
     ]
    }
   ],
   "source": [
    "theta, cost_history = minimize_gradient(y_data, x_data_minmax, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97,  63, 104,  67,  66,  93, 108,  37,  44,  43,  75, 148,  13,\n",
       "        87,  82, 132,   4, 101, 139,  98,  62,  81, 106,  11,  58,   7,\n",
       "       147,  10,   7, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0,150,30)\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1,\n",
       "       1, 0, 1, 0, 2, 0, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(softmax(x_data_minmax[rand_index].dot(theta.T)),axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1,\n",
       "       2, 0, 1, 0, 2, 0, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(y_data[rand_index],axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == y_true) / len(rand_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
